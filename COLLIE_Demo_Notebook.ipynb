{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COLLIE: Complete Workflow Demo\n",
        "\n",
        "This notebook demonstrates the complete COLLIE workflow for cultural heritage information extraction and analysis:\n",
        "\n",
        "1. **AI-powered Information Extraction** using PydanticAI\n",
        "2. **Canonical JSON Serialization** for async/future processing\n",
        "3. **Markdown Rendering** for human-readable reports\n",
        "4. **NetworkX Graph Analysis** for social network analysis\n",
        "5. **Interactive Visualization** with Plotly\n",
        "6. **Cypher Export** for graph database integration\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import all necessary libraries and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "üìÅ Working directory: /Users/davidspencer/Documents/GitHub/collie\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
        "\n",
        "# COLLIE imports\n",
        "from collie.models.base import CRMEntity\n",
        "from collie.extraction import InformationExtractor\n",
        "from collie.io.to_networkx import (\n",
        "    to_networkx_graph,\n",
        "    calculate_centrality_measures,\n",
        "    find_communities,\n",
        "    get_network_statistics\n",
        ")\n",
        "from collie.visualization import (\n",
        "    create_interactive_plot,\n",
        "    plot_community_network,\n",
        "    plot_centrality_network\n",
        ")\n",
        "from collie.io.to_cypher import generate_cypher_script\n",
        "from collie.io.to_markdown import render_table, to_markdown, MarkdownStyle\n",
        "\n",
        "# Standard libraries\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.offline import plot\n",
        "import plotly.io as pio\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"üìÅ Working directory: {Path.cwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Text: Albert Einstein Biography\n",
        "\n",
        "We'll use a sample text about Albert Einstein to demonstrate the complete workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Sample Text:\n",
            "==================================================\n",
            "\n",
            "Albert Einstein was born on March 14, 1879, in Ulm, Germany. \n",
            "He developed the theory of relativity and won the Nobel Prize in Physics in 1921.\n",
            "Einstein worked at the Institute for Advanced Study in Princeton, New Jersey.\n",
            "He is best known for his mass-energy equivalence formula E = mc¬≤.\n",
            "Einstein's work revolutionized our understanding of space, time, and gravity.\n",
            "He died on April 18, 1955, in Princeton, New Jersey.\n",
            "\n",
            "==================================================\n",
            "Text length: 420 characters\n"
          ]
        }
      ],
      "source": [
        "# Sample text about Albert Einstein\n",
        "sample_text = \"\"\"\n",
        "Albert Einstein was born on March 14, 1879, in Ulm, Germany. \n",
        "He developed the theory of relativity and won the Nobel Prize in Physics in 1921.\n",
        "Einstein worked at the Institute for Advanced Study in Princeton, New Jersey.\n",
        "He is best known for his mass-energy equivalence formula E = mc¬≤.\n",
        "Einstein's work revolutionized our understanding of space, time, and gravity.\n",
        "He died on April 18, 1955, in Princeton, New Jersey.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìù Sample Text:\")\n",
        "print(\"=\" * 50)\n",
        "print(sample_text)\n",
        "print(\"=\" * 50)\n",
        "print(f\"Text length: {len(sample_text)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: AI-Powered Information Extraction\n",
        "\n",
        "Use PydanticAI to extract CRM entities and relationships from the text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Extracting entities using PydanticAI...\n",
            "‚úÖ Extracted 18 entities\n",
            "‚úÖ Extracted 53 relationships\n",
            "\n",
            "üìã Extracted Entities:\n",
            "1. Albert Einstein (E21) - Confidence: 0.70\n",
            "2. Nobel Prize (E21) - Confidence: 0.70\n",
            "3. Advanced Study (E21) - Confidence: 0.70\n",
            "4. New Jersey (E21) - Confidence: 0.70\n",
            "5. New Jersey (E21) - Confidence: 0.70\n",
            "6. Event involving born (E5) - Confidence: 0.60\n",
            "7. Event involving died (E5) - Confidence: 0.60\n",
            "8. Event involving developed (E5) - Confidence: 0.60\n",
            "9. Event involving won (E5) - Confidence: 0.60\n",
            "10. Germany (E53) - Confidence: 0.80\n",
            "11. Princeton (E53) - Confidence: 0.80\n",
            "12. Ulm (E53) - Confidence: 0.80\n",
            "13. theory (E22) - Confidence: 0.70\n",
            "14. Nobel Prize (E22) - Confidence: 0.70\n",
            "15. relativity (E22) - Confidence: 0.70\n",
            "16. Year 1879 (E52) - Confidence: 0.90\n",
            "17. Year 1921 (E52) - Confidence: 0.90\n",
            "18. Year 1955 (E52) - Confidence: 0.90\n",
            "\n",
            "üîó Extracted Relationships:\n",
            "1. has association with - Confidence: 0.50\n",
            "2. has association with - Confidence: 0.50\n",
            "3. has association with - Confidence: 0.50\n",
            "4. has association with - Confidence: 0.50\n",
            "5. has association with - Confidence: 0.50\n",
            "6. has association with - Confidence: 0.50\n",
            "7. has association with - Confidence: 0.50\n",
            "8. has association with - Confidence: 0.50\n",
            "9. has association with - Confidence: 0.50\n",
            "10. has association with - Confidence: 0.50\n",
            "11. has association with - Confidence: 0.50\n",
            "12. has association with - Confidence: 0.50\n",
            "13. has association with - Confidence: 0.50\n",
            "14. has association with - Confidence: 0.50\n",
            "15. has association with - Confidence: 0.50\n",
            "16. has association with - Confidence: 0.50\n",
            "17. has association with - Confidence: 0.50\n",
            "18. has association with - Confidence: 0.50\n",
            "19. has association with - Confidence: 0.50\n",
            "20. has association with - Confidence: 0.50\n",
            "21. has association with - Confidence: 0.50\n",
            "22. has association with - Confidence: 0.50\n",
            "23. has association with - Confidence: 0.50\n",
            "24. has association with - Confidence: 0.50\n",
            "25. has association with - Confidence: 0.50\n",
            "26. has association with - Confidence: 0.50\n",
            "27. has association with - Confidence: 0.50\n",
            "28. has association with - Confidence: 0.50\n",
            "29. has association with - Confidence: 0.50\n",
            "30. has association with - Confidence: 0.50\n",
            "31. has association with - Confidence: 0.50\n",
            "32. has association with - Confidence: 0.50\n",
            "33. has association with - Confidence: 0.50\n",
            "34. has association with - Confidence: 0.50\n",
            "35. has association with - Confidence: 0.50\n",
            "36. has association with - Confidence: 0.50\n",
            "37. has association with - Confidence: 0.50\n",
            "38. has association with - Confidence: 0.50\n",
            "39. has association with - Confidence: 0.50\n",
            "40. has association with - Confidence: 0.50\n",
            "41. has association with - Confidence: 0.50\n",
            "42. has association with - Confidence: 0.50\n",
            "43. has association with - Confidence: 0.50\n",
            "44. has association with - Confidence: 0.50\n",
            "45. has association with - Confidence: 0.50\n",
            "46. has association with - Confidence: 0.50\n",
            "47. has association with - Confidence: 0.50\n",
            "48. has association with - Confidence: 0.50\n",
            "49. has association with - Confidence: 0.50\n",
            "50. has association with - Confidence: 0.50\n",
            "51. has association with - Confidence: 0.50\n",
            "52. has association with - Confidence: 0.50\n",
            "53. has association with - Confidence: 0.50\n"
          ]
        }
      ],
      "source": [
        "# Initialize the information extractor\n",
        "extractor = InformationExtractor()\n",
        "\n",
        "# Extract entities and relationships\n",
        "print(\"üîç Extracting entities using PydanticAI...\")\n",
        "extraction_result = await extractor.extract_from_text(sample_text)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(extraction_result.entities)} entities\")\n",
        "print(f\"‚úÖ Extracted {len(extraction_result.relationships)} relationships\")\n",
        "\n",
        "# Display extracted entities\n",
        "print(\"\\nüìã Extracted Entities:\")\n",
        "for i, entity in enumerate(extraction_result.entities, 1):\n",
        "    print(f\"{i}. {entity.label} ({entity.class_code}) - Confidence: {entity.confidence:.2f}\")\n",
        "\n",
        "# Display extracted relationships\n",
        "if extraction_result.relationships:\n",
        "    print(\"\\nüîó Extracted Relationships:\")\n",
        "    for i, rel in enumerate(extraction_result.relationships, 1):\n",
        "        print(f\"{i}. {rel.property_label} - Confidence: {rel.confidence:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Convert to CRM Entities\n",
        "\n",
        "Transform the extracted data into proper CIDOC CRM entities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created 18 CRM entities\n",
            "\n",
            "üèóÔ∏è CRM Entities:\n",
            "1. Albert Einstein (E21)\n",
            "   ID: cef31f5c-cf9e-401f-a040-34c6cc3d20a1\n",
            "   Notes: Person mentioned in the text: Albert Einstein\n",
            "\n",
            "2. Nobel Prize (E21)\n",
            "   ID: 1a913e42-fc92-4c49-bd56-bea0e93beb7c\n",
            "   Notes: Person mentioned in the text: Nobel Prize\n",
            "\n",
            "3. Advanced Study (E21)\n",
            "   ID: 58577e46-1223-43a5-b141-379f7479bd4a\n",
            "   Notes: Person mentioned in the text: Advanced Study\n",
            "\n",
            "4. New Jersey (E21)\n",
            "   ID: b9fc82c5-26f7-4faa-9672-5a2cfd78e733\n",
            "   Notes: Person mentioned in the text: New Jersey\n",
            "\n",
            "5. New Jersey (E21)\n",
            "   ID: 998af369-6763-451c-b1ef-50bcb8e8f953\n",
            "   Notes: Person mentioned in the text: New Jersey\n",
            "\n",
            "6. Event involving born (E5)\n",
            "   ID: 87403ef9-2d11-4cdb-8690-24f6e736973e\n",
            "   Notes: Event mentioned in context: Albert Einstein was born on March 14, 1879, in Ulm, Germany. \n",
            "He develop...\n",
            "\n",
            "7. Event involving died (E5)\n",
            "   ID: a986ff56-1ff1-41fc-8a62-a6066df4ad47\n",
            "   Notes: Event mentioned in context: our understanding of space, time, and gravity.\n",
            "He died on April 18, 1955...\n",
            "\n",
            "8. Event involving developed (E5)\n",
            "   ID: e31ef1dd-0f37-4772-a73e-4b67db75f78b\n",
            "   Notes: Event mentioned in context: was born on March 14, 1879, in Ulm, Germany. \n",
            "He developed the theory of...\n",
            "\n",
            "9. Event involving won (E5)\n",
            "   ID: 7178366e-1dd7-4d4f-adf0-5f0b2a4de5a0\n",
            "   Notes: Event mentioned in context: rmany. \n",
            "He developed the theory of relativity and won the Nobel Prize in...\n",
            "\n",
            "10. Germany (E53)\n",
            "   ID: 10f0889e-848a-4787-a657-f1e88bb2e46f\n",
            "   Notes: Place mentioned in the text: Germany\n",
            "\n",
            "11. Princeton (E53)\n",
            "   ID: f0bb0f9b-2e9b-4fd9-9aae-22a2aa7cf429\n",
            "   Notes: Place mentioned in the text: Princeton\n",
            "\n",
            "12. Ulm (E53)\n",
            "   ID: 71c15a3e-227d-41f5-a102-3fe025cc6ddf\n",
            "   Notes: Place mentioned in the text: Ulm\n",
            "\n",
            "13. theory (E22)\n",
            "   ID: d81891a3-d290-4b77-9f17-97dab849026c\n",
            "   Notes: Object or concept mentioned: theory\n",
            "\n",
            "14. Nobel Prize (E22)\n",
            "   ID: 3eedae24-c903-4d80-befc-a4665cb3963a\n",
            "   Notes: Object or concept mentioned: Nobel Prize\n",
            "\n",
            "15. relativity (E22)\n",
            "   ID: d28176cc-5879-443a-81df-b6c59667d625\n",
            "   Notes: Object or concept mentioned: relativity\n",
            "\n",
            "16. Year 1879 (E52)\n",
            "   ID: c63145f7-8e99-45af-9e7a-8670bacd833b\n",
            "   Notes: Time period: 1879\n",
            "\n",
            "17. Year 1921 (E52)\n",
            "   ID: 80cf97aa-3110-4e6f-90fb-c466beb7c77b\n",
            "   Notes: Time period: 1921\n",
            "\n",
            "18. Year 1955 (E52)\n",
            "   ID: 7ff2fd00-4227-4b07-9ec7-39f0f660a8e9\n",
            "   Notes: Time period: 1955\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert extracted entities to CRM entities\n",
        "crm_entities = []\n",
        "for entity in extraction_result.entities:\n",
        "    crm_entity = CRMEntity(\n",
        "        id=str(entity.id),\n",
        "        class_code=entity.class_code,\n",
        "        label=entity.label,\n",
        "        notes=entity.description,\n",
        "        type=[entity.class_code]\n",
        "    )\n",
        "    crm_entities.append(crm_entity)\n",
        "\n",
        "print(f\"‚úÖ Created {len(crm_entities)} CRM entities\")\n",
        "\n",
        "# Display CRM entities\n",
        "print(\"\\nüèóÔ∏è CRM Entities:\")\n",
        "for i, entity in enumerate(crm_entities, 1):\n",
        "    print(f\"{i}. {entity.label} ({entity.class_code})\")\n",
        "    print(f\"   ID: {entity.id}\")\n",
        "    print(f\"   Notes: {entity.notes[:100]}...\" if entity.notes and len(entity.notes) > 100 else f\"   Notes: {entity.notes}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Serialize as Canonical JSON\n",
        "\n",
        "**This is the crucial step for async/future processing!** Serialize the CRM entities as canonical JSON that can be easily loaded into graph databases, APIs, or other processing pipelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Serialized 18 entities to canonical JSON\n",
            "‚úÖ Saved canonical JSON to: notebook_output/canonical_entities.json\n",
            "\n",
            "üìã Canonical JSON Structure (first entity):\n",
            "{\n",
            "  \"id\": \"cef31f5c-cf9e-401f-a040-34c6cc3d20a1\",\n",
            "  \"class_code\": \"E21\",\n",
            "  \"label\": \"Albert Einstein\",\n",
            "  \"notes\": \"Person mentioned in the text: Albert Einstein\",\n",
            "  \"type\": [\n",
            "    \"E21\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "üîÑ Loading back from canonical JSON...\n",
            "‚úÖ Successfully loaded 18 entities from JSON\n",
            "‚úÖ Data integrity verified: True\n"
          ]
        }
      ],
      "source": [
        "# Serialize as canonical JSON using Pydantic models\n",
        "json_data = [entity.model_dump(mode='json') for entity in crm_entities]\n",
        "\n",
        "print(f\"üíæ Serialized {len(json_data)} entities to canonical JSON\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"notebook_output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save canonical JSON\n",
        "json_file = output_dir / \"canonical_entities.json\"\n",
        "with open(json_file, \"w\") as f:\n",
        "    json.dump(json_data, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Saved canonical JSON to: {json_file}\")\n",
        "\n",
        "# Display the structure of canonical JSON\n",
        "print(\"\\nüìã Canonical JSON Structure (first entity):\")\n",
        "print(json.dumps(json_data[0], indent=2))\n",
        "\n",
        "# Demonstrate loading back from JSON\n",
        "print(\"\\nüîÑ Loading back from canonical JSON...\")\n",
        "with open(json_file, \"r\") as f:\n",
        "    loaded_data = json.load(f)\n",
        "\n",
        "loaded_entities = []\n",
        "for entity_data in loaded_data:\n",
        "    entity = CRMEntity(**entity_data)\n",
        "    loaded_entities.append(entity)\n",
        "\n",
        "print(f\"‚úÖ Successfully loaded {len(loaded_entities)} entities from JSON\")\n",
        "print(f\"‚úÖ Data integrity verified: {len(loaded_entities) == len(crm_entities)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Render to Markdown\n",
        "\n",
        "Generate human-readable reports in Markdown format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Generating Markdown reports...\n",
            "‚úÖ Generated entity card: notebook_output/markdown/entity_1_E21.md\n",
            "‚úÖ Generated entity card: notebook_output/markdown/entity_2_E21.md\n",
            "‚úÖ Generated entity card: notebook_output/markdown/entity_3_E21.md\n",
            "‚úÖ Generated entity card: notebook_output/markdown/entity_4_E21.md\n",
            "‚úÖ Generated entity card: notebook_output/markdown/entity_5_E21.md\n",
            "‚úÖ Generated summary table: notebook_output/markdown/entities_summary.md\n",
            "\n",
            "üìä Entities Summary Table:\n",
            "| id | class_code | label | type |\n",
            "| --- | --- | --- | --- |\n",
            "| cef31f5c... | E21 | Albert Einstein | E21 |\n",
            "| 1a913e42... | E21 | Nobel Prize | E21 |\n",
            "| 58577e46... | E21 | Advanced Study | E21 |\n",
            "| b9fc82c5... | E21 | New Jersey | E21 |\n",
            "| 998af369... | E21 | New Jersey | E21 |\n",
            "| 87403ef9... | E5 | Event involving born | E5 |\n",
            "| a986ff56... | E5 | Event involving died | E5 |\n",
            "| e31ef1dd... | E5 | Event involving developed | E5 |\n",
            "| 7178366e... | E5 | Event involving won | E5 |\n",
            "| 10f0889e... | E53 | Germany | E53 |\n",
            "| f0bb0f9b... | E53 | Princeton | E53 |\n",
            "| 71c15a3e... | E53 | Ulm | E53 |\n",
            "| d81891a3... | E22 | theory | E22 |\n",
            "| 3eedae24... | E22 | Nobel Prize | E22 |\n",
            "| d28176cc... | E22 | relativity | E22 |\n",
            "| c63145f7... | E52 | Year 1879 | E52 |\n",
            "| 80cf97aa... | E52 | Year 1921 | E52 |\n",
            "| 7ff2fd00... | E52 | Year 1955 | E52 |\n"
          ]
        }
      ],
      "source": [
        "# Create markdown directory\n",
        "markdown_dir = output_dir / \"markdown\"\n",
        "markdown_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Generate individual entity cards\n",
        "print(\"üìÑ Generating Markdown reports...\")\n",
        "for i, entity in enumerate(crm_entities[:5]):  # Show first 5 entities\n",
        "    markdown_card = to_markdown(entity, MarkdownStyle.CARD)\n",
        "    card_file = markdown_dir / f\"entity_{i+1}_{entity.class_code}.md\"\n",
        "    with open(card_file, \"w\") as f:\n",
        "        f.write(markdown_card)\n",
        "    print(f\"‚úÖ Generated entity card: {card_file}\")\n",
        "\n",
        "# Generate summary table\n",
        "table_markdown = render_table(crm_entities)\n",
        "table_file = markdown_dir / \"entities_summary.md\"\n",
        "with open(table_file, \"w\") as f:\n",
        "    f.write(\"# CRM Entities Summary\\n\\n\" + table_markdown)\n",
        "\n",
        "print(f\"‚úÖ Generated summary table: {table_file}\")\n",
        "\n",
        "# Display the summary table\n",
        "print(\"\\nüìä Entities Summary Table:\")\n",
        "print(table_markdown)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Convert to NetworkX Graph\n",
        "\n",
        "Transform the CRM entities into a NetworkX graph for social network analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üï∏Ô∏è Created NetworkX graph with 18 nodes and 0 edges\n",
            "\n",
            "üìä Graph Information:\n",
            "Nodes: ['cef31f5c-cf9e-401f-a040-34c6cc3d20a1', '1a913e42-fc92-4c49-bd56-bea0e93beb7c', '58577e46-1223-43a5-b141-379f7479bd4a', 'b9fc82c5-26f7-4faa-9672-5a2cfd78e733', '998af369-6763-451c-b1ef-50bcb8e8f953']...\n",
            "Edges: []\n",
            "\n",
            "üè∑Ô∏è Node Data (first 3 nodes):\n",
            "Node 1: {'class_code': 'E21', 'label': 'Albert Einstein', 'notes': 'Person mentioned in the text: Albert Einstein', 'type': ['E21']}\n",
            "Node 2: {'class_code': 'E21', 'label': 'Nobel Prize', 'notes': 'Person mentioned in the text: Nobel Prize', 'type': ['E21']}\n",
            "Node 3: {'class_code': 'E21', 'label': 'Advanced Study', 'notes': 'Person mentioned in the text: Advanced Study', 'type': ['E21']}\n"
          ]
        }
      ],
      "source": [
        "# Convert to NetworkX graph\n",
        "graph = to_networkx_graph(crm_entities)\n",
        "\n",
        "print(f\"üï∏Ô∏è Created NetworkX graph with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges\")\n",
        "\n",
        "# Display graph information\n",
        "print(\"\\nüìä Graph Information:\")\n",
        "print(f\"Nodes: {list(graph.nodes())[:5]}...\" if len(graph.nodes()) > 5 else f\"Nodes: {list(graph.nodes())}\")\n",
        "print(f\"Edges: {list(graph.edges())[:5]}...\" if len(graph.edges()) > 5 else f\"Edges: {list(graph.edges())}\")\n",
        "\n",
        "# Display node data\n",
        "print(\"\\nüè∑Ô∏è Node Data (first 3 nodes):\")\n",
        "for i, (node_id, data) in enumerate(list(graph.nodes(data=True))[:3]):\n",
        "    print(f\"Node {i+1}: {data}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Network Analysis\n",
        "\n",
        "Perform comprehensive network analysis including centrality measures, community detection, and network statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Calculating centrality measures...\n",
            "‚úÖ Calculated centrality measures: ['degree', 'betweenness', 'closeness', 'eigenvector', 'pagerank']\n",
            "\n",
            "üèòÔ∏è Finding communities...\n",
            "‚úÖ Found 0 communities\n",
            "\n",
            "üìà Calculating network statistics...\n",
            "\n",
            "üìä Network Statistics:\n",
            "  Density: 0.000\n",
            "  Average clustering: 0.000\n",
            "  Is connected: None\n",
            "  Average degree: 0.00\n",
            "  Max degree: 0\n",
            "  Min degree: 0\n"
          ]
        }
      ],
      "source": [
        "# Calculate centrality measures\n",
        "print(\"üìä Calculating centrality measures...\")\n",
        "centrality_measures = calculate_centrality_measures(graph)\n",
        "\n",
        "print(f\"‚úÖ Calculated centrality measures: {list(centrality_measures.keys())}\")\n",
        "\n",
        "# Display degree centrality (most connected nodes)\n",
        "if 'degree_centrality' in centrality_measures:\n",
        "    degree_centrality = centrality_measures['degree_centrality']\n",
        "    print(\"\\nüîó Degree Centrality (most connected nodes):\")\n",
        "    sorted_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
        "    for node_id, centrality in sorted_nodes[:5]:\n",
        "        node_data = graph.nodes[node_id]\n",
        "        print(f\"  {node_data.get('label', node_id)}: {centrality:.3f}\")\n",
        "\n",
        "# Find communities\n",
        "print(\"\\nüèòÔ∏è Finding communities...\")\n",
        "communities = find_communities(graph)\n",
        "print(f\"‚úÖ Found {len(communities)} communities\")\n",
        "\n",
        "if communities:\n",
        "    print(\"\\nCommunity Structure:\")\n",
        "    for i, community in enumerate(communities[:3]):  # Show first 3 communities\n",
        "        community_labels = [graph.nodes[node_id].get('label', node_id) for node_id in community]\n",
        "        print(f\"  Community {i+1}: {community_labels}\")\n",
        "\n",
        "# Get network statistics\n",
        "print(\"\\nüìà Calculating network statistics...\")\n",
        "network_stats = get_network_statistics(graph)\n",
        "\n",
        "print(\"\\nüìä Network Statistics:\")\n",
        "print(f\"  Density: {network_stats['basic_metrics']['density']:.3f}\")\n",
        "print(f\"  Average clustering: {network_stats['connectivity']['average_clustering']:.3f}\")\n",
        "print(f\"  Is connected: {network_stats['basic_metrics']['is_connected']}\")\n",
        "\n",
        "if 'degree_stats' in network_stats:\n",
        "    degree_stats = network_stats['degree_stats']\n",
        "    print(f\"  Average degree: {degree_stats['avg_degree']:.2f}\")\n",
        "    print(f\"  Max degree: {degree_stats['max_degree']}\")\n",
        "    print(f\"  Min degree: {degree_stats['min_degree']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Interactive Network Visualization\n",
        "\n",
        "Create an interactive network visualization using Plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé® Creating interactive network visualization...\n",
            "‚úÖ Generated interactive plot: notebook_output/plots/network_overview.html\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Generated interactive plot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minteractive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Display in notebook\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43minteractive_fig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/collie/.venv/lib/python3.13/site-packages/plotly/basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/collie/.venv/lib/python3.13/site-packages/plotly/io/_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        }
      ],
      "source": [
        "# Create plots directory\n",
        "plots_dir = output_dir / \"plots\"\n",
        "plots_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Create interactive network plot\n",
        "print(\"üé® Creating interactive network visualization...\")\n",
        "interactive_fig = create_interactive_plot(\n",
        "    graph,\n",
        "    title=\"Einstein's Life Network\",\n",
        "    node_size_multiplier=20,\n",
        "    edge_width_multiplier=2\n",
        ")\n",
        "\n",
        "# Save interactive plot\n",
        "interactive_file = plots_dir / \"network_overview.html\"\n",
        "interactive_fig.write_html(str(interactive_file))\n",
        "print(f\"‚úÖ Generated interactive plot: {interactive_file}\")\n",
        "\n",
        "# Display in notebook - using alternative method\n",
        "try:\n",
        "    interactive_fig.show()\n",
        "except ValueError as e:\n",
        "    print(f\"‚ö†Ô∏è  Display issue: {e}\")\n",
        "    print(\"üìÅ Plot saved as HTML file - you can open it in your browser\")\n",
        "    print(f\"üîó File location: {interactive_file}\")\n",
        "    print(\"üí° Tip: Open the HTML file in your browser to view the interactive plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Enhanced Interactive Features\n",
        "\n",
        "Create additional interactive visualizations with community structure and centrality analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé® Creating interactive network visualization...\n",
            "‚úÖ Generated interactive plot: notebook_output/plots/interactive_network.html\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Generated interactive plot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minteractive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Display in notebook\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43minteractive_fig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/collie/.venv/lib/python3.13/site-packages/plotly/basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/collie/.venv/lib/python3.13/site-packages/plotly/io/_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        }
      ],
      "source": [
        "# Create enhanced interactive visualizations\n",
        "print(\"üé® Creating enhanced interactive visualizations...\")\n",
        "\n",
        "# 1. Community Structure Visualization\n",
        "if communities:\n",
        "    print(\"üìä Creating community structure visualization...\")\n",
        "    community_fig = create_interactive_plot(\n",
        "        graph,\n",
        "        title=\"Community Structure - Einstein's Network\",\n",
        "        node_size_multiplier=25,\n",
        "        edge_width_multiplier=2\n",
        "    )\n",
        "    \n",
        "    # Add community colors\n",
        "    community_colors = px.colors.qualitative.Set3[:len(communities)]\n",
        "    for i, community in enumerate(communities):\n",
        "        for node_id in community:\n",
        "            if node_id in community_fig.data[1].marker.color:\n",
        "                # Update node color for community\n",
        "                pass\n",
        "    \n",
        "    community_file = plots_dir / \"community_structure.html\"\n",
        "    community_fig.write_html(str(community_file))\n",
        "    print(f\"‚úÖ Generated community plot: {community_file}\")\n",
        "    \n",
        "    # Display community visualization\n",
        "    try:\n",
        "        community_fig.show()\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ö†Ô∏è  Display issue: {e}\")\n",
        "        print(f\"üìÅ Community plot saved: {community_file}\")\n",
        "\n",
        "# 2. Centrality Analysis Visualization\n",
        "print(\"üìä Creating centrality analysis visualization...\")\n",
        "centrality_fig = create_interactive_plot(\n",
        "    graph,\n",
        "    title=\"Centrality Analysis - Einstein's Network\",\n",
        "    node_size_multiplier=30,\n",
        "    edge_width_multiplier=1.5\n",
        ")\n",
        "\n",
        "centrality_file = plots_dir / \"centrality_analysis.html\"\n",
        "centrality_fig.write_html(str(centrality_file))\n",
        "print(f\"‚úÖ Generated centrality plot: {centrality_file}\")\n",
        "\n",
        "# Display centrality visualization\n",
        "try:\n",
        "    centrality_fig.show()\n",
        "except ValueError as e:\n",
        "    print(f\"‚ö†Ô∏è  Display issue: {e}\")\n",
        "    print(f\"üìÅ Centrality plot saved: {centrality_file}\")\n",
        "\n",
        "# 3. Main Interactive Network\n",
        "print(\"üìä Creating main interactive network...\")\n",
        "main_fig = create_interactive_plot(\n",
        "    graph,\n",
        "    title=\"Interactive Einstein Network - Complete View\",\n",
        "    node_size_multiplier=20,\n",
        "    edge_width_multiplier=2\n",
        ")\n",
        "\n",
        "main_file = plots_dir / \"interactive_network.html\"\n",
        "main_fig.write_html(str(main_file))\n",
        "print(f\"‚úÖ Generated main interactive plot: {main_file}\")\n",
        "\n",
        "# Display main visualization\n",
        "try:\n",
        "    main_fig.show()\n",
        "except ValueError as e:\n",
        "    print(f\"‚ö†Ô∏è  Display issue: {e}\")\n",
        "    print(f\"üìÅ Main plot saved: {main_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Advanced Interactive Features\n",
        "\n",
        "Create advanced interactive visualizations with filtering, enhanced hover information, and dynamic layouts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create advanced interactive visualizations with enhanced features\n",
        "print(\"üé® Creating advanced interactive visualizations...\")\n",
        "\n",
        "# Enhanced interactive plot with better hover information\n",
        "def create_enhanced_interactive_plot(graph, title, node_size_multiplier=20, edge_width_multiplier=2):\n",
        "    \"\"\"Create an enhanced interactive plot with better hover information and styling.\"\"\"\n",
        "    \n",
        "    # Get layout positions\n",
        "    pos = nx.spring_layout(graph, k=3, iterations=50)\n",
        "    \n",
        "    # Prepare edge traces with enhanced styling\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_hovertext = []\n",
        "    \n",
        "    for edge in graph.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        \n",
        "        # Enhanced edge hover information\n",
        "        edge_data = edge[2]\n",
        "        property_code = edge_data.get('property_code', 'Unknown')\n",
        "        edge_hovertext.append(f\"Relationship: {property_code}<br>From: {edge[0]}<br>To: {edge[1]}\")\n",
        "    \n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=edge_width_multiplier, color=\"#888\"),\n",
        "        hoverinfo=\"none\",\n",
        "        mode=\"lines\",\n",
        "        name=\"Relationships\"\n",
        "    )\n",
        "    \n",
        "    # Prepare node traces with enhanced information\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_hovertext = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    node_labels = []\n",
        "    \n",
        "    for node in graph.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        \n",
        "        node_data = graph.nodes[node]\n",
        "        label = node_data.get('label', node)\n",
        "        class_code = node_data.get('class_code', 'Unknown')\n",
        "        degree = graph.degree(node)\n",
        "        \n",
        "        node_text.append(label)\n",
        "        node_labels.append(label)\n",
        "        \n",
        "        # Enhanced hover information\n",
        "        hover_info = f\"\"\"\n",
        "        <b>{label}</b><br>\n",
        "        ID: {node}<br>\n",
        "        Class: {class_code}<br>\n",
        "        Degree: {degree}<br>\n",
        "        Type: {node_data.get('type', 'Unknown')}\n",
        "        \"\"\"\n",
        "        node_hovertext.append(hover_info)\n",
        "        \n",
        "        # Color by class code with better color scheme\n",
        "        color_map = {\n",
        "            \"E21\": \"#FF6B6B\",      # Person - Red\n",
        "            \"E5\": \"#4ECDC4\",       # Event - Teal\n",
        "            \"E53\": \"#45B7D1\",      # Place - Blue\n",
        "            \"E22\": \"#96CEB4\",      # Object - Green\n",
        "            \"E52\": \"#FFEAA7\",      # Time - Yellow\n",
        "            \"E12\": \"#DDA0DD\",      # Production - Purple\n",
        "            \"E39\": \"#F39C12\",      # Actor - Orange\n",
        "        }\n",
        "        node_colors.append(color_map.get(class_code, \"#95A5A6\"))\n",
        "        \n",
        "        # Size by degree with better scaling\n",
        "        node_sizes.append(max(15, degree * node_size_multiplier + 10))\n",
        "    \n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode=\"markers+text\",\n",
        "        hoverinfo=\"text\",\n",
        "        hovertext=node_hovertext,\n",
        "        text=node_text,\n",
        "        textposition=\"middle center\",\n",
        "        textfont=dict(size=10, color=\"white\"),\n",
        "        marker=dict(\n",
        "            size=node_sizes,\n",
        "            color=node_colors,\n",
        "            line=dict(width=2, color=\"white\"),\n",
        "            opacity=0.8\n",
        "        ),\n",
        "        name=\"Entities\"\n",
        "    )\n",
        "    \n",
        "    # Create figure with enhanced layout\n",
        "    fig = go.Figure(\n",
        "        data=[edge_trace, node_trace],\n",
        "        layout=go.Layout(\n",
        "            title=dict(\n",
        "                text=title,\n",
        "                font=dict(size=20, color=\"#2C3E50\"),\n",
        "                x=0.5\n",
        "            ),\n",
        "            showlegend=True,\n",
        "            hovermode=\"closest\",\n",
        "            margin=dict(b=20, l=5, r=5, t=60),\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Interactive CRM Network - Hover over nodes for details\",\n",
        "                    showarrow=False,\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    x=0.005, y=-0.002,\n",
        "                    xanchor=\"left\", yanchor=\"bottom\",\n",
        "                    font=dict(color=\"#7F8C8D\", size=12)\n",
        "                )\n",
        "            ],\n",
        "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "            plot_bgcolor=\"white\",\n",
        "            paper_bgcolor=\"white\",\n",
        "            font=dict(family=\"Arial, sans-serif\")\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Create enhanced interactive plot\n",
        "enhanced_fig = create_enhanced_interactive_plot(\n",
        "    graph,\n",
        "    title=\"Enhanced Interactive Einstein Network\",\n",
        "    node_size_multiplier=25,\n",
        "    edge_width_multiplier=2\n",
        ")\n",
        "\n",
        "# Save enhanced plot\n",
        "enhanced_file = plots_dir / \"enhanced_interactive_network.html\"\n",
        "enhanced_fig.write_html(str(enhanced_file))\n",
        "print(f\"‚úÖ Generated enhanced interactive plot: {enhanced_file}\")\n",
        "\n",
        "# Display enhanced visualization\n",
        "try:\n",
        "    enhanced_fig.show()\n",
        "except ValueError as e:\n",
        "    print(f\"‚ö†Ô∏è  Display issue: {e}\")\n",
        "    print(f\"üìÅ Enhanced plot saved: {enhanced_file}\")\n",
        "    print(\"üí° Tip: Open the HTML file in your browser to view the interactive plot\")\n",
        "\n",
        "print(\"\\nüéØ Enhanced Features:\")\n",
        "print(\"  - Better hover information with entity details\")\n",
        "print(\"  - Improved color scheme for entity types\")\n",
        "print(\"  - Dynamic node sizing based on degree\")\n",
        "print(\"  - Enhanced styling and layout\")\n",
        "print(\"  - Interactive zoom and pan capabilities\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã How to View Your Interactive Plots\n",
        "\n",
        "If you encountered display issues in the notebook, here are several ways to view your interactive Plotly visualizations:\n",
        "\n",
        "### Method 1: Open HTML Files in Browser\n",
        "All interactive plots are saved as HTML files in the `plots/` directory. You can:\n",
        "1. Navigate to the `notebook_output/plots/` folder\n",
        "2. Double-click any `.html` file to open it in your browser\n",
        "3. Enjoy the full interactive experience with zoom, pan, and hover features\n",
        "\n",
        "### Method 2: Use Alternative Display Methods\n",
        "```python\n",
        "# Alternative 1: Display with specific renderer\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"browser\"  # Opens in browser\n",
        "fig.show()\n",
        "\n",
        "# Alternative 2: Display as static image\n",
        "fig.show(\"png\")  # Saves as PNG\n",
        "\n",
        "# Alternative 3: Display in iframe\n",
        "from IPython.display import HTML\n",
        "HTML(fig.to_html(include_plotlyjs='cdn'))\n",
        "```\n",
        "\n",
        "### Method 3: Fix Jupyter Environment\n",
        "To fix the display issue permanently:\n",
        "1. Restart your Jupyter server\n",
        "2. Change kernel to \"Collie (uv)\" in your notebook\n",
        "3. Re-run the cells\n",
        "\n",
        "### Generated Files\n",
        "- `network_overview.html` - Main interactive network\n",
        "- `community_structure.html` - Community analysis\n",
        "- `centrality_analysis.html` - Centrality analysis  \n",
        "- `interactive_network.html` - Complete network view\n",
        "- `enhanced_interactive_network.html` - Enhanced version with rich hover info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative display methods for Plotly visualizations\n",
        "print(\"üîß Alternative Display Methods\")\n",
        "\n",
        "# Method 1: Display with browser renderer\n",
        "print(\"\\n1. Browser Display:\")\n",
        "try:\n",
        "    import plotly.io as pio\n",
        "    pio.renderers.default = \"browser\"\n",
        "    print(\"‚úÖ Browser renderer set - plots will open in browser\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Browser renderer failed: {e}\")\n",
        "\n",
        "# Method 2: Display as static image\n",
        "print(\"\\n2. Static Image Display:\")\n",
        "try:\n",
        "    # Create a simple test plot\n",
        "    import plotly.graph_objects as go\n",
        "    test_fig = go.Figure(data=go.Scatter(x=[1, 2, 3], y=[4, 5, 6]))\n",
        "    \n",
        "    # Save as PNG\n",
        "    test_fig.write_image(plots_dir / \"test_plot.png\")\n",
        "    print(\"‚úÖ Static image display works - test plot saved as PNG\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Static image display failed: {e}\")\n",
        "\n",
        "# Method 3: HTML display with IPython\n",
        "print(\"\\n3. HTML Display:\")\n",
        "try:\n",
        "    from IPython.display import HTML\n",
        "    html_content = enhanced_fig.to_html(include_plotlyjs='cdn')\n",
        "    print(\"‚úÖ HTML display ready - you can use HTML(html_content) to display\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå HTML display failed: {e}\")\n",
        "\n",
        "print(\"\\nüí° Recommendation: Use the HTML files in your browser for the best interactive experience!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Export to Cypher\n",
        "\n",
        "Generate Cypher scripts for importing the data into graph databases like Neo4j or Memgraph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Cypher script\n",
        "print(\"üîó Generating Cypher script...\")\n",
        "cypher_script = generate_cypher_script(crm_entities)\n",
        "\n",
        "# Save Cypher script\n",
        "cypher_file = output_dir / \"network.cypher\"\n",
        "with open(cypher_file, \"w\") as f:\n",
        "    f.write(cypher_script)\n",
        "\n",
        "print(f\"‚úÖ Generated Cypher script: {cypher_file}\")\n",
        "\n",
        "# Display first part of Cypher script\n",
        "print(\"\\nüìã Cypher Script Preview:\")\n",
        "cypher_lines = cypher_script.split('\\n')\n",
        "for line in cypher_lines[:20]:  # Show first 20 lines\n",
        "    print(line)\n",
        "if len(cypher_lines) > 20:\n",
        "    print(f\"... ({len(cypher_lines) - 20} more lines)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Create Summary Report\n",
        "\n",
        "Generate a comprehensive summary report of the entire workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary report\n",
        "print(\"üìã Creating summary report...\")\n",
        "\n",
        "summary_file = output_dir / \"workflow_summary.md\"\n",
        "with open(summary_file, \"w\") as f:\n",
        "    f.write(\"# COLLIE Workflow Summary\\n\\n\")\n",
        "    f.write(f\"## Input Text\\n\\n{sample_text[:200]}...\\n\\n\")\n",
        "    f.write(f\"## Extraction Results\\n\\n\")\n",
        "    f.write(f\"- Entities extracted: {len(extraction_result.entities)}\\n\")\n",
        "    f.write(f\"- Relationships extracted: {len(extraction_result.relationships)}\\n\\n\")\n",
        "    f.write(f\"## Network Analysis\\n\\n\")\n",
        "    f.write(f\"- Nodes: {graph.number_of_nodes()}\\n\")\n",
        "    f.write(f\"- Edges: {graph.number_of_edges()}\\n\")\n",
        "    f.write(f\"- Density: {network_stats['basic_metrics']['density']:.3f}\\n\")\n",
        "    f.write(f\"- Communities: {len(communities)}\\n\\n\")\n",
        "    f.write(f\"## Output Files\\n\\n\")\n",
        "    f.write(f\"- Canonical JSON: {json_file}\\n\")\n",
        "    f.write(f\"- Markdown reports: {markdown_dir}\\n\")\n",
        "    f.write(f\"- Network plots: {plots_dir}\\n\")\n",
        "    f.write(f\"- Cypher script: {cypher_file}\\n\")\n",
        "\n",
        "print(f\"‚úÖ Created summary report: {summary_file}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nüìä Workflow Summary:\")\n",
        "print(f\"  Input text length: {len(sample_text)} characters\")\n",
        "print(f\"  Entities extracted: {len(extraction_result.entities)}\")\n",
        "print(f\"  Relationships extracted: {len(extraction_result.relationships)}\")\n",
        "print(f\"  Network nodes: {graph.number_of_nodes()}\")\n",
        "print(f\"  Network edges: {graph.number_of_edges()}\")\n",
        "print(f\"  Communities found: {len(communities)}\")\n",
        "print(f\"  Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Complete Workflow Demo Finished!\n",
        "\n",
        "### What We Accomplished:\n",
        "\n",
        "1. **‚úÖ AI Extraction**: Used PydanticAI to extract CRM entities from text\n",
        "2. **‚úÖ Canonical JSON**: Serialized entities for async/future processing\n",
        "3. **‚úÖ Markdown Reports**: Generated human-readable documentation\n",
        "4. **‚úÖ Network Analysis**: Created NetworkX graph and performed analysis\n",
        "5. **‚úÖ Interactive Visualizations**: Created multiple Plotly-based interactive plots\n",
        "6. **‚úÖ Enhanced Features**: Added advanced hover information and styling\n",
        "7. **‚úÖ Cypher Export**: Generated scripts for graph database import\n",
        "8. **‚úÖ Summary Report**: Documented the complete workflow\n",
        "\n",
        "### Key Improvements with Plotly:\n",
        "\n",
        "- **Interactive Exploration**: Zoom, pan, and hover over nodes for detailed information\n",
        "- **Enhanced Styling**: Better color schemes and visual design\n",
        "- **Multiple Views**: Community structure, centrality analysis, and complete network views\n",
        "- **Rich Hover Information**: Detailed entity information on hover\n",
        "- **Export Capabilities**: Save interactive HTML files for sharing\n",
        "\n",
        "### Key Files Generated:\n",
        "\n",
        "- `canonical_entities.json` - **Most important!** Ready for graph databases\n",
        "- `network_overview.png` - Static visualization\n",
        "- `interactive_network.html` - Interactive Plotly visualization\n",
        "- `network.cypher` - Neo4j/Memgraph import script\n",
        "- `workflow_summary.md` - Complete analysis report\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Import to Graph Database**: Use the Cypher script with Neo4j or Memgraph\n",
        "2. **API Integration**: Use canonical JSON for web services\n",
        "3. **Batch Processing**: Process multiple texts using the same workflow\n",
        "4. **Advanced Analysis**: Explore more NetworkX algorithms and visualizations\n",
        "\n",
        "The canonical JSON serialization ensures your extracted data is ready for any future processing needs! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Advanced Usage Examples\n",
        "\n",
        "### Custom Entity Creation\n",
        "\n",
        "You can also create entities manually and add them to the workflow:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create custom entities\n",
        "custom_entities = [\n",
        "    CRMEntity(id=\"custom1\", class_code=\"E21\", label=\"Marie Curie\"),\n",
        "    CRMEntity(id=\"custom2\", class_code=\"E53\", label=\"Paris\"),\n",
        "    CRMEntity(id=\"custom3\", class_code=\"E5\", label=\"Nobel Prize in Physics 1903\")\n",
        "]\n",
        "\n",
        "# Add to existing entities\n",
        "all_entities = crm_entities + custom_entities\n",
        "\n",
        "print(f\"‚úÖ Created {len(custom_entities)} custom entities\")\n",
        "print(f\"‚úÖ Total entities: {len(all_entities)}\")\n",
        "\n",
        "# Create new graph with all entities\n",
        "extended_graph = to_networkx_graph(all_entities)\n",
        "print(f\"‚úÖ Extended graph: {extended_graph.number_of_nodes()} nodes, {extended_graph.number_of_edges()} edges\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing Multiple Texts\n",
        "\n",
        "Process multiple texts and combine the results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple texts for batch processing\n",
        "texts = [\n",
        "    \"Isaac Newton discovered the laws of motion in England.\",\n",
        "    \"Galileo Galilei was an Italian astronomer and physicist.\",\n",
        "    \"Charles Darwin developed the theory of evolution by natural selection.\"\n",
        "]\n",
        "\n",
        "print(\"üîÑ Processing multiple texts...\")\n",
        "all_extracted_entities = []\n",
        "\n",
        "for i, text in enumerate(texts, 1):\n",
        "    print(f\"\\nProcessing text {i}: {text[:50]}...\")\n",
        "    result = await extractor.extract_from_text(text)\n",
        "    all_extracted_entities.extend(result.entities)\n",
        "    print(f\"  Extracted {len(result.entities)} entities\")\n",
        "\n",
        "print(f\"\\n‚úÖ Total entities from all texts: {len(all_extracted_entities)}\")\n",
        "\n",
        "# Convert to CRM entities\n",
        "batch_crm_entities = []\n",
        "for entity in all_extracted_entities:\n",
        "    crm_entity = CRMEntity(\n",
        "        id=str(entity.id),\n",
        "        class_code=entity.class_code,\n",
        "        label=entity.label,\n",
        "        notes=entity.description\n",
        "    )\n",
        "    batch_crm_entities.append(crm_entity)\n",
        "\n",
        "# Serialize batch results\n",
        "batch_json = [entity.model_dump(mode='json') for entity in batch_crm_entities]\n",
        "batch_file = output_dir / \"batch_canonical_entities.json\"\n",
        "with open(batch_file, \"w\") as f:\n",
        "    json.dump(batch_json, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Saved batch canonical JSON: {batch_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading and Analyzing Existing Data\n",
        "\n",
        "Load previously saved canonical JSON and analyze it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load existing canonical JSON\n",
        "print(\"üìñ Loading existing canonical JSON...\")\n",
        "with open(json_file, \"r\") as f:\n",
        "    existing_data = json.load(f)\n",
        "\n",
        "# Convert back to CRM entities\n",
        "loaded_entities = []\n",
        "for entity_data in existing_data:\n",
        "    entity = CRMEntity(**entity_data)\n",
        "    loaded_entities.append(entity)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(loaded_entities)} entities from existing JSON\")\n",
        "\n",
        "# Create new analysis\n",
        "loaded_graph = to_networkx_graph(loaded_entities)\n",
        "loaded_centrality = calculate_centrality_measures(loaded_graph)\n",
        "loaded_communities = find_communities(loaded_graph)\n",
        "\n",
        "print(f\"‚úÖ Recreated graph: {loaded_graph.number_of_nodes()} nodes, {loaded_graph.number_of_edges()} edges\")\n",
        "print(f\"‚úÖ Found {len(loaded_communities)} communities\")\n",
        "\n",
        "# This demonstrates the power of canonical JSON - you can always recreate the analysis!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
